{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15b173e-4c31-4b88-9a0f-3d3277a1f96a",
   "metadata": {},
   "source": [
    "# Statistical analysis of a fracture network\n",
    "\n",
    "This notebook will show how to perform statistical analysis of the analyized network. It will show how to:\n",
    "+ Fit different distributions to the dataset\n",
    "+ Plot summary plots for each fitted distribution\n",
    "+ Visually compare different fits using PIT\n",
    "+ Show and export statistical summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3122f6d-7e05-46c2-bf97-c4a523477ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fracability.examples import data  # import the path of the sample data\n",
    "from fracability import Entities, Plotters  # import the Entities class\n",
    "from fracability.operations import Statistics\n",
    "\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "# The following is only for jupyter to avoid matplotlib inline plots\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c12566-698d-4b39-aae7-47403f21eddd",
   "metadata": {},
   "source": [
    "## Import the Pontrelli quarry Set a and calculate the topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c33a71a-33ff-4ed6-8ff2-e937d29f6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Calculating intersections: 1944/1945\n",
      "\n",
      "\n",
      "Analyzing nodes:20982/20983\r"
     ]
    }
   ],
   "source": [
    "pontrelli_data = data.Pontrelli()\n",
    "data_dict = pontrelli_data.data_dict  # Get dict of paths for the data\n",
    "\n",
    "# Create the fractures and boundary objects. \n",
    "set_a = Entities.Fractures(shp=data_dict['Set_a.shp'], set_n=1)  # to add your data put the absolute path of the shp file\n",
    "\n",
    "boundary = Entities.Boundary(shp=data_dict['Interpretation_boundary.shp'], group_n=1)\n",
    "\n",
    "fracture_net = Entities.FractureNetwork()\n",
    "\n",
    "fracture_net.add_fractures(set_a)\n",
    "fracture_net.add_boundaries(boundary)\n",
    "\n",
    "fracture_net.calculate_topology()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178f379-1136-44ee-b582-b4022afeec1c",
   "metadata": {},
   "source": [
    "## NetworkFitter \n",
    "\n",
    "The network fitter class is responsible of running the statistical analysis on the fracture network. There are different options:\n",
    "1. use_survival: Boolean flag to use survival (True) or treat the data as if there were no censoring (False). Default is True. \n",
    "2. complete_only: Boolean flag to use only complete measurements (True) or all the dataset (False). This flag is used only when use_survival is False. Default is False.\n",
    "3. use_AIC: Boolean flag to use AIC (true) or AICc (false) for model selection. Default is True\n",
    "\n",
    "\n",
    "These options are useful to compare different ways of fitting the data with survival analysis however we strongly suggest to always use survival analysis since in case of no censoring the final results will be the same as the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4829d42-ada1-47da-85c9-213cc98ec076",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = Statistics.NetworkFitter(fracture_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad090e-855a-4429-b5f9-4a86432bbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitter.net_data.data)\n",
    "print(fitter.net_data.censoring_percentage)  # get the % of censored values\n",
    "print(fitter.net_data.mean) # get the sample mean (i.e. ignoring censoring) \n",
    "print(fitter.net_data.std) # get the sample std\n",
    "print(fitter.net_data.mode)  # get the sample mode\n",
    "# ... See docs for the full list of sample statitistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f2f594-2423-4a5d-bad6-47e9ba78736f",
   "metadata": {},
   "source": [
    "We can also estimate the empirical cumulative or survival curve using Kaplan Meier and compare it to a ecdf calculated on a \"ignoring censoring\" dataset (i.e. all the lentghs without censoring flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38632b10-61ba-45e9-a0b7-d4d9377103f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KM = fitter.net_data.ecdf\n",
    "lengths = fitter.network_data.lengths  # get only the length data (without knowing which one are censored or not)\n",
    "ignore_ecdf = ss.ecdf(lengths).cdf\n",
    "plt.plot(lengths, KM, '-k')\n",
    "plt.plot(lengths, ignore_ecdf.probabilities, '--k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764c325-a97f-47cd-ab44-a890fce3ca94",
   "metadata": {},
   "source": [
    "### Fit different distributions\n",
    "\n",
    "All the rv_continous distribution present in scipy are valid (https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions).\n",
    "\n",
    "Each time a fit is run the Akaike, Kolmogorov-Smirnov, Koziol and Green and Anderson Darling distances are calculated and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7b36c7-0251-4d3a-8447-747ec6051020",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.fit('lognorm')\n",
    "fitter.fit('expon')\n",
    "fitter.fit('norm')\n",
    "fitter.fit('gengamma')\n",
    "fitter.fit('powerlaw')\n",
    "fitter.fit('weibull_min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bfe48d-139b-4554-988d-c5ff5ecb82a4",
   "metadata": {},
   "source": [
    "### Plot the different models using PIT and show the model rank table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea5930-2f01-452e-bb7a-8242c4556c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.matplot_stats_uniform(fitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0e81c-fef2-4861-95da-98e5caacf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.fit_records(sort_by='Akaike').iloc[:,:-1] # the iloc is to remove the last column that is not useful in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8ce62-0340-4519-9d7c-6b8770d9290f",
   "metadata": {},
   "source": [
    "This table can also be saved as csv, excel or directly to clipboard in a excel friendly format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3da8ba-0075-4e4c-9315-5b8daaf86b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.fit_result_to_csv('test_export.csv')\n",
    "fitter.fit_result_to_excel('test_export.xlsx')\n",
    "fitter.fit_result_to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef31302-5eae-45bb-a82c-99e2cfba1297",
   "metadata": {},
   "source": [
    "### Plot a summary plot of the best ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd844d0-ea57-444c-9c41-ec712d9b1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotters.matplot_stats_summary(fitter, best=True,sort_by='Mean_rank')\n",
    "Plotters.matplot_stats_summary(fitter, best=False,sort_by='Mean_rank') # plot them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca949e-81ee-4dbf-8463-03d04af906e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
